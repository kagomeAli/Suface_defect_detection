{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcb7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import numpy as np\n",
    "import os, gc, cv2, shutil,platform, datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose,Dropout, concatenate, BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tensorflow_addons.layers import InstanceNormalization, GroupNormalization, SpatialPyramidPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras, gzip, pickle\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import levit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09796fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kaka\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84dcaa6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ad8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_image(root_path, IMG_SIZE):\n",
    "    # 获取该目录下所有的文件名称和目录名称\n",
    "    class_list = os.listdir(root_path)\n",
    "    training_data = []\n",
    "    for c_type in class_list:\n",
    "        files_list = os.listdir(f'{root_path}/{c_type}')\n",
    "        for file in files_list:\n",
    "            if \"jp\" in file:\n",
    "                image = cv2.imread(f'{root_path}/{c_type}/{file}', cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, IMG_SIZE)\n",
    "                \n",
    "#                 image= local_binary_pattern(image, 8, 1.0, 'ror')\n",
    "                \n",
    "                image_lr = np.fliplr(image)\n",
    "                image_tb = np.flip(image)\n",
    "                image_tb_lr = np.flip(image_lr)\n",
    "                training_data.append([image_lr, c_type])\n",
    "                training_data.append([image_tb_lr, c_type])\n",
    "                training_data.append([image_tb, c_type])\n",
    "                training_data.append([image, c_type])\n",
    "    return training_data\n",
    "\n",
    "def get_file_image_test(root_path, IMG_SIZE):\n",
    "    # 获取该目录下所有的文件名称和目录名称\n",
    "    test_files = []\n",
    "    class_list = os.listdir(root_path)\n",
    "    testing_data = []\n",
    "    for c_type in class_list:\n",
    "        files_list = os.listdir(f'{root_path}/{c_type}')\n",
    "        for file in files_list:\n",
    "             if \"jp\" in file:\n",
    "                test_files.append(file)\n",
    "                image = cv2.imread(f'{root_path}/{c_type}/{file}', cv2.IMREAD_GRAYSCALE)\n",
    "                image = cv2.resize(image, IMG_SIZE)\n",
    "#                 image= local_binary_pattern(image, 8, 1.0, 'ror')\n",
    "                testing_data.append([image, c_type])\n",
    "    return testing_data, test_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759fef3",
   "metadata": {},
   "source": [
    "## Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3362e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path params\n",
    "DATASET_TYPE = 'FabricDataset'\n",
    "DATASET_PATH= f'C:/Users/kaka/PycharmProjects/pythonProject/AOI/ICLR2024/dataset/{DATASET_TYPE}/'\n",
    "TRAIN_TYPE = '243'\n",
    "IMG_SIZE = (400, 320)\n",
    "CLASSRS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36aa91",
   "metadata": {},
   "source": [
    "## handle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f8d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_file_image(f'{DATASET_PATH}/{TRAIN_TYPE}/TRAIN', IMG_SIZE)\n",
    "testing_data, test_files = get_file_image_test(f'{DATASET_PATH}/{TRAIN_TYPE}/TEST', IMG_SIZE)\n",
    "\n",
    "\n",
    "train_image = []\n",
    "train_label = []\n",
    "test_image = []\n",
    "test_label = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    train_image.append(features)\n",
    "    train_label.append(label)\n",
    "\n",
    "for features, label in testing_data:\n",
    "    test_image.append(features)\n",
    "    test_label.append(label)\n",
    "    \n",
    "    \n",
    "\n",
    "train_image = np.array(train_image).reshape(len(training_data), IMG_SIZE[0], IMG_SIZE[1], 1)\n",
    "train_image = train_image.astype('float32') / 255\n",
    "\n",
    "test_image = np.array(test_image).reshape(len(testing_data), IMG_SIZE[0], IMG_SIZE[1], 1)\n",
    "test_image = test_image.astype('float32') / 255\n",
    "\n",
    "test_label = np.array(test_label)\n",
    "test_label = test_label.astype('float32')\n",
    "\n",
    "train_label = np.array(train_label)\n",
    "train_label = train_label.astype('float32')\n",
    "\n",
    "\n",
    "train_image, train_label = shuffle(train_image, train_label, random_state=8)\n",
    "\n",
    "train_label_categ = tf.keras.utils.to_categorical(train_label, num_classes=CLASSRS)\n",
    "test_label_categ = tf.keras.utils.to_categorical(test_label, num_classes=CLASSRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb9bd22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_categ[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9d8b2",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d197267",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"Tensorboard/levit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99fe943",
   "metadata": {},
   "source": [
    "tensorboard --logdir=f'C:/Users/kaka/PycharmProjects/pythonProject/AOI/ICPR2023/model/Tensorboard/levit/20230309-163422'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae9d1a",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12031060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "LEARNING_RATE = 8e-4\n",
    "BATCH = 128\n",
    "EPOCHS = 300\n",
    "PATIENCE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52baaea",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "703a262b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47452/292466854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n\u001b[0m\u001b[0;32m     13\u001b[0m                                 \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                 save_freq=4)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filepath' is not defined"
     ]
    }
   ],
   "source": [
    "# Early Stop\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=PATIENCE,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                                save_best_only=True, save_weights_only=False, mode='auto', \n",
    "                                save_freq=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e9e7748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Load pretrained from: C:\\Users\\kaka\\.keras\\models\\levit256_imagenet.h5\n",
      "WARNING:tensorflow:Skipping loading weights for layer #2 (named stem_1_conv) due to mismatch in shape for weight stem_1_conv/kernel:0. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (32, 3, 3, 3)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #24 (named stack1_block1_attn_pos) due to mismatch in shape for weight stack1_block1_attn_pos/positional_embedding:0. Weight expects shape (500, 4). Received saved weight with shape (196, 4)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #46 (named stack1_block2_attn_pos) due to mismatch in shape for weight stack1_block2_attn_pos/positional_embedding:0. Weight expects shape (500, 4). Received saved weight with shape (196, 4)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #68 (named stack1_block3_attn_pos) due to mismatch in shape for weight stack1_block3_attn_pos/positional_embedding:0. Weight expects shape (500, 4). Received saved weight with shape (196, 4)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #90 (named stack1_block4_attn_pos) due to mismatch in shape for weight stack1_block4_attn_pos/positional_embedding:0. Weight expects shape (500, 4). Received saved weight with shape (196, 4)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #119 (named stack1_downsample_attn_pos) due to mismatch in shape for weight stack1_downsample_attn_pos/positional_embedding:0. Weight expects shape (500, 8). Received saved weight with shape (196, 8)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #140 (named stack2_block1_attn_pos) due to mismatch in shape for weight stack2_block1_attn_pos/positional_embedding:0. Weight expects shape (130, 6). Received saved weight with shape (49, 6)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #162 (named stack2_block2_attn_pos) due to mismatch in shape for weight stack2_block2_attn_pos/positional_embedding:0. Weight expects shape (130, 6). Received saved weight with shape (49, 6)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #184 (named stack2_block3_attn_pos) due to mismatch in shape for weight stack2_block3_attn_pos/positional_embedding:0. Weight expects shape (130, 6). Received saved weight with shape (49, 6)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #206 (named stack2_block4_attn_pos) due to mismatch in shape for weight stack2_block4_attn_pos/positional_embedding:0. Weight expects shape (130, 6). Received saved weight with shape (49, 6)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #235 (named stack2_downsample_attn_pos) due to mismatch in shape for weight stack2_downsample_attn_pos/positional_embedding:0. Weight expects shape (130, 12). Received saved weight with shape (49, 12)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #256 (named stack3_block1_attn_pos) due to mismatch in shape for weight stack3_block1_attn_pos/positional_embedding:0. Weight expects shape (35, 8). Received saved weight with shape (16, 8)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #278 (named stack3_block2_attn_pos) due to mismatch in shape for weight stack3_block2_attn_pos/positional_embedding:0. Weight expects shape (35, 8). Received saved weight with shape (16, 8)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #300 (named stack3_block3_attn_pos) due to mismatch in shape for weight stack3_block3_attn_pos/positional_embedding:0. Weight expects shape (35, 8). Received saved weight with shape (16, 8)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #322 (named stack3_block4_attn_pos) due to mismatch in shape for weight stack3_block4_attn_pos/positional_embedding:0. Weight expects shape (35, 8). Received saved weight with shape (16, 8)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #340 (named head) due to mismatch in shape for weight head/kernel:0. Weight expects shape (512, 5). Received saved weight with shape (512, 1000)\n",
      "WARNING:tensorflow:Skipping loading weights for layer #340 (named head) due to mismatch in shape for weight head/bias:0. Weight expects shape (5,). Received saved weight with shape (1000,)\n",
      ">>>> Reload mismatched weights: 224 -> (400, 320)\n",
      ">>>> Reload layer: stack1_block1_attn_pos\n",
      ">>>> Reload layer: stack1_block2_attn_pos\n",
      ">>>> Reload layer: stack1_block3_attn_pos\n",
      ">>>> Reload layer: stack1_block4_attn_pos\n",
      ">>>> Reload layer: stack1_downsample_attn_pos\n",
      ">>>> Reload layer: stack2_block1_attn_pos\n",
      ">>>> Reload layer: stack2_block2_attn_pos\n",
      ">>>> Reload layer: stack2_block3_attn_pos\n",
      ">>>> Reload layer: stack2_block4_attn_pos\n",
      ">>>> Reload layer: stack2_downsample_attn_pos\n",
      ">>>> Reload layer: stack3_block1_attn_pos\n",
      ">>>> Reload layer: stack3_block2_attn_pos\n",
      ">>>> Reload layer: stack3_block3_attn_pos\n",
      ">>>> Reload layer: stack3_block4_attn_pos\n",
      "Epoch 1/300\n",
      "3/3 [==============================] - 11s 923ms/step - loss: 0.3445 - accuracy: 0.3310 - val_loss: 0.7345 - val_accuracy: 0.2266\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.2352 - accuracy: 0.5951 - val_loss: 447.4684 - val_accuracy: 0.2578\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.2475 - accuracy: 0.6761 - val_loss: 5196.9038 - val_accuracy: 0.2266\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.2134 - accuracy: 0.7606 - val_loss: 10515.6680 - val_accuracy: 0.1797\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1572 - accuracy: 0.7852 - val_loss: 18759.1270 - val_accuracy: 0.1562\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1555 - accuracy: 0.7852 - val_loss: 44999.6289 - val_accuracy: 0.2266\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1440 - accuracy: 0.8239 - val_loss: 76810.0938 - val_accuracy: 0.2266\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.1601 - accuracy: 0.7570 - val_loss: 324518.4062 - val_accuracy: 0.1719\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.1282 - accuracy: 0.8099 - val_loss: 545376.7500 - val_accuracy: 0.2188\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.1335 - accuracy: 0.8521 - val_loss: 458737.6250 - val_accuracy: 0.1719\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.1097 - accuracy: 0.8556 - val_loss: 485160.0625 - val_accuracy: 0.1172\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.1000 - accuracy: 0.8627 - val_loss: 411429.1875 - val_accuracy: 0.1172\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.1106 - accuracy: 0.8662 - val_loss: 495971.2812 - val_accuracy: 0.1797\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0918 - accuracy: 0.8908 - val_loss: 1304568.2500 - val_accuracy: 0.2734\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0869 - accuracy: 0.8979 - val_loss: 1454922.7500 - val_accuracy: 0.2656\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0793 - accuracy: 0.9155 - val_loss: 1446556.0000 - val_accuracy: 0.1797\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0806 - accuracy: 0.9014 - val_loss: 1071012.1250 - val_accuracy: 0.1484\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0830 - accuracy: 0.9190 - val_loss: 337111.4375 - val_accuracy: 0.1250\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0707 - accuracy: 0.9296 - val_loss: 164224.0312 - val_accuracy: 0.1641\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0734 - accuracy: 0.9155 - val_loss: 59130.5625 - val_accuracy: 0.2734\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0815 - accuracy: 0.9437 - val_loss: 20366.8301 - val_accuracy: 0.4453\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0809 - accuracy: 0.9437 - val_loss: 1507.9261 - val_accuracy: 0.4922\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0802 - accuracy: 0.9577 - val_loss: 166.3590 - val_accuracy: 0.5703\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0725 - accuracy: 0.9401 - val_loss: 268.0558 - val_accuracy: 0.6562\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0554 - accuracy: 0.9401 - val_loss: 4.4329 - val_accuracy: 0.7422\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0605 - accuracy: 0.9577 - val_loss: 2.7014 - val_accuracy: 0.7578\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0789 - accuracy: 0.9472 - val_loss: 3.3955 - val_accuracy: 0.7109\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0528 - accuracy: 0.9683 - val_loss: 0.2100 - val_accuracy: 0.7344\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0719 - accuracy: 0.9613 - val_loss: 0.3283 - val_accuracy: 0.7891\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.0576 - accuracy: 0.9437 - val_loss: 0.4399 - val_accuracy: 0.7656\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0484 - accuracy: 0.9859 - val_loss: 0.2936 - val_accuracy: 0.6875\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0640 - accuracy: 0.9718 - val_loss: 0.2209 - val_accuracy: 0.7031\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0611 - accuracy: 0.9683 - val_loss: 0.1936 - val_accuracy: 0.7578\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0621 - accuracy: 0.9542 - val_loss: 0.1608 - val_accuracy: 0.7812\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0628 - accuracy: 0.9542 - val_loss: 0.0974 - val_accuracy: 0.8047\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0772 - accuracy: 0.9754 - val_loss: 0.1074 - val_accuracy: 0.7969\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0686 - accuracy: 0.9683 - val_loss: 0.0968 - val_accuracy: 0.7656\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0683 - accuracy: 0.9648 - val_loss: 0.0764 - val_accuracy: 0.8125\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0754 - accuracy: 0.9683 - val_loss: 0.0946 - val_accuracy: 0.7812\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0704 - accuracy: 0.9542 - val_loss: 0.2621 - val_accuracy: 0.7266\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0644 - accuracy: 0.9472 - val_loss: 0.3443 - val_accuracy: 0.6484\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0760 - accuracy: 0.9507 - val_loss: 0.2370 - val_accuracy: 0.7344\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0751 - accuracy: 0.9577 - val_loss: 0.0873 - val_accuracy: 0.8203\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0614 - accuracy: 0.9437 - val_loss: 0.0656 - val_accuracy: 0.8438\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0500 - accuracy: 0.9754 - val_loss: 0.0687 - val_accuracy: 0.8281\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0434 - accuracy: 0.9613 - val_loss: 0.0870 - val_accuracy: 0.8203\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0696 - accuracy: 0.9648 - val_loss: 0.0787 - val_accuracy: 0.8047\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0480 - accuracy: 0.9789 - val_loss: 0.0825 - val_accuracy: 0.7969\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0560 - accuracy: 0.9789 - val_loss: 0.0769 - val_accuracy: 0.7891\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0599 - accuracy: 0.9683 - val_loss: 0.0679 - val_accuracy: 0.7891\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0564 - accuracy: 0.9613 - val_loss: 0.0564 - val_accuracy: 0.8359\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.0657 - accuracy: 0.9613 - val_loss: 0.0655 - val_accuracy: 0.8281\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0536 - accuracy: 0.9613 - val_loss: 0.0968 - val_accuracy: 0.8047\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.0518 - accuracy: 0.9718 - val_loss: 0.0708 - val_accuracy: 0.8438\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0449 - accuracy: 0.9718 - val_loss: 0.0619 - val_accuracy: 0.8516\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.0395 - accuracy: 0.9859 - val_loss: 0.0576 - val_accuracy: 0.8672\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0477 - accuracy: 0.9754 - val_loss: 0.0621 - val_accuracy: 0.8516\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0496 - accuracy: 0.9718 - val_loss: 0.0602 - val_accuracy: 0.8359\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0524 - accuracy: 0.9683 - val_loss: 0.0668 - val_accuracy: 0.8047\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0449 - accuracy: 0.9754 - val_loss: 0.0690 - val_accuracy: 0.8203\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0366 - accuracy: 0.9824 - val_loss: 0.0596 - val_accuracy: 0.8125\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0522 - accuracy: 0.9683 - val_loss: 0.0532 - val_accuracy: 0.8359\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0377 - accuracy: 0.9754 - val_loss: 0.1072 - val_accuracy: 0.8359\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.0613 - val_accuracy: 0.8359\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0565 - accuracy: 0.9577 - val_loss: 0.0863 - val_accuracy: 0.8594\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0521 - accuracy: 0.9789 - val_loss: 0.0603 - val_accuracy: 0.8438\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0401 - accuracy: 0.9754 - val_loss: 0.0610 - val_accuracy: 0.8359\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0384 - accuracy: 0.9824 - val_loss: 0.0601 - val_accuracy: 0.8359\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.0601 - val_accuracy: 0.8125\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0481 - accuracy: 0.9894 - val_loss: 0.0663 - val_accuracy: 0.7891\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0470 - accuracy: 0.9754 - val_loss: 0.0641 - val_accuracy: 0.8203\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0477 - accuracy: 0.9718 - val_loss: 0.0626 - val_accuracy: 0.8359\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0484 - accuracy: 0.9648 - val_loss: 0.0711 - val_accuracy: 0.8594\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0349 - accuracy: 0.9754 - val_loss: 0.0725 - val_accuracy: 0.8516\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0364 - accuracy: 0.9789 - val_loss: 0.0922 - val_accuracy: 0.8438\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0478 - accuracy: 0.9683 - val_loss: 0.0738 - val_accuracy: 0.8281\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.0775 - val_accuracy: 0.8281\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0561 - accuracy: 0.9683 - val_loss: 0.0816 - val_accuracy: 0.8281\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0493 - accuracy: 0.9789 - val_loss: 0.0761 - val_accuracy: 0.8359\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0500 - accuracy: 0.9789 - val_loss: 0.0758 - val_accuracy: 0.8203\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0558 - accuracy: 0.9824 - val_loss: 0.0602 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.0600 - val_accuracy: 0.8203\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0526 - accuracy: 0.9683 - val_loss: 0.1188 - val_accuracy: 0.8203\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0364 - accuracy: 0.9824 - val_loss: 0.1576 - val_accuracy: 0.8047\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0523 - accuracy: 0.9648 - val_loss: 0.1008 - val_accuracy: 0.8281\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0563 - accuracy: 0.9507 - val_loss: 0.0651 - val_accuracy: 0.8750\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0549 - accuracy: 0.9789 - val_loss: 0.0892 - val_accuracy: 0.8672\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0857 - val_accuracy: 0.8594\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0565 - accuracy: 0.9648 - val_loss: 0.0897 - val_accuracy: 0.8438\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0666 - accuracy: 0.9754 - val_loss: 0.0696 - val_accuracy: 0.8516\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0534 - accuracy: 0.9789 - val_loss: 0.0739 - val_accuracy: 0.8438\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0566 - accuracy: 0.9683 - val_loss: 0.0876 - val_accuracy: 0.8281\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0721 - accuracy: 0.9613 - val_loss: 0.0590 - val_accuracy: 0.8359\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0560 - accuracy: 0.9754 - val_loss: 0.0566 - val_accuracy: 0.8281\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0499 - accuracy: 0.9718 - val_loss: 0.0558 - val_accuracy: 0.8281\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0357 - accuracy: 0.9789 - val_loss: 0.0776 - val_accuracy: 0.8203\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0433 - accuracy: 0.9718 - val_loss: 0.0705 - val_accuracy: 0.8438\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0489 - accuracy: 0.9754 - val_loss: 0.0680 - val_accuracy: 0.8438\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 0.0641 - val_accuracy: 0.8359\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0481 - accuracy: 0.9789 - val_loss: 0.0535 - val_accuracy: 0.8359\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0503 - accuracy: 0.9718 - val_loss: 0.0562 - val_accuracy: 0.8203\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0522 - accuracy: 0.9718 - val_loss: 0.0561 - val_accuracy: 0.8203\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0646 - accuracy: 0.9718 - val_loss: 0.0586 - val_accuracy: 0.8359\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0459 - accuracy: 0.9789 - val_loss: 0.0996 - val_accuracy: 0.8516\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.0777 - val_accuracy: 0.8672\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0484 - accuracy: 0.9789 - val_loss: 0.0616 - val_accuracy: 0.8516\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0530 - accuracy: 0.9824 - val_loss: 0.0540 - val_accuracy: 0.8516\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0422 - accuracy: 0.9718 - val_loss: 0.0527 - val_accuracy: 0.8281\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0450 - accuracy: 0.9718 - val_loss: 0.0539 - val_accuracy: 0.8125\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0478 - accuracy: 0.9789 - val_loss: 0.0526 - val_accuracy: 0.8125\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0401 - accuracy: 0.9789 - val_loss: 0.0663 - val_accuracy: 0.8203\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0464 - accuracy: 0.9577 - val_loss: 0.0744 - val_accuracy: 0.8125\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0413 - accuracy: 0.9824 - val_loss: 0.0517 - val_accuracy: 0.8672\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0352 - accuracy: 0.9754 - val_loss: 0.0490 - val_accuracy: 0.8594\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0443 - accuracy: 0.9683 - val_loss: 0.0661 - val_accuracy: 0.8516\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0520 - val_accuracy: 0.8516\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0397 - accuracy: 0.9718 - val_loss: 0.0518 - val_accuracy: 0.8359\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0413 - accuracy: 0.9824 - val_loss: 0.0539 - val_accuracy: 0.8203\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.0558 - val_accuracy: 0.8047\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0446 - accuracy: 0.9754 - val_loss: 0.0567 - val_accuracy: 0.8047\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.0564 - val_accuracy: 0.7891\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0517 - accuracy: 0.9683 - val_loss: 0.0570 - val_accuracy: 0.8125\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0284 - accuracy: 0.9859 - val_loss: 0.0537 - val_accuracy: 0.8125\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0407 - accuracy: 0.9789 - val_loss: 0.0525 - val_accuracy: 0.8125\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0340 - accuracy: 0.9824 - val_loss: 0.0514 - val_accuracy: 0.8438\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0321 - accuracy: 0.9894 - val_loss: 0.0600 - val_accuracy: 0.8594\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0356 - accuracy: 0.9789 - val_loss: 0.0490 - val_accuracy: 0.8672\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.0523 - val_accuracy: 0.8672\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 1s 373ms/step - loss: 0.0372 - accuracy: 0.9789 - val_loss: 0.0500 - val_accuracy: 0.8594\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0409 - accuracy: 0.9824 - val_loss: 0.0524 - val_accuracy: 0.8438\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0406 - accuracy: 0.9789 - val_loss: 0.0758 - val_accuracy: 0.8203\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0430 - accuracy: 0.9754 - val_loss: 0.0657 - val_accuracy: 0.8203\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0436 - accuracy: 0.9789 - val_loss: 0.0693 - val_accuracy: 0.8125\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0348 - accuracy: 0.9930 - val_loss: 0.0823 - val_accuracy: 0.8203\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0347 - accuracy: 0.9824 - val_loss: 0.0736 - val_accuracy: 0.8203\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0360 - accuracy: 0.9859 - val_loss: 0.0782 - val_accuracy: 0.8359\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.0506 - val_accuracy: 0.8359\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.0483 - val_accuracy: 0.8438\n",
      "Epoch 139/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0331 - accuracy: 0.9930 - val_loss: 0.0693 - val_accuracy: 0.8281\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0375 - accuracy: 0.9859 - val_loss: 0.0500 - val_accuracy: 0.8359\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0359 - accuracy: 0.9965 - val_loss: 0.0506 - val_accuracy: 0.8281\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0412 - accuracy: 0.9718 - val_loss: 0.0496 - val_accuracy: 0.8359\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0365 - accuracy: 0.9754 - val_loss: 0.0515 - val_accuracy: 0.8203\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0348 - accuracy: 0.9789 - val_loss: 0.0518 - val_accuracy: 0.8438\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.0447 - val_accuracy: 0.8672\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0316 - accuracy: 0.9894 - val_loss: 0.0463 - val_accuracy: 0.8750\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0395 - accuracy: 0.9824 - val_loss: 0.0490 - val_accuracy: 0.8750\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0266 - accuracy: 0.9965 - val_loss: 0.0495 - val_accuracy: 0.8672\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0285 - accuracy: 0.9824 - val_loss: 0.0553 - val_accuracy: 0.8516\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0373 - accuracy: 0.9859 - val_loss: 0.0462 - val_accuracy: 0.8359\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0355 - accuracy: 0.9789 - val_loss: 0.0485 - val_accuracy: 0.8125\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0334 - accuracy: 0.9859 - val_loss: 0.0512 - val_accuracy: 0.8047\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0474 - accuracy: 0.9859 - val_loss: 0.0510 - val_accuracy: 0.8203\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.0494 - val_accuracy: 0.8203\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0366 - accuracy: 0.9789 - val_loss: 0.0484 - val_accuracy: 0.8750\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0429 - accuracy: 0.9754 - val_loss: 0.0485 - val_accuracy: 0.8750\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0379 - accuracy: 0.9930 - val_loss: 0.0487 - val_accuracy: 0.8750\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0470 - val_accuracy: 0.8594\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.0457 - val_accuracy: 0.8359\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0394 - accuracy: 0.9859 - val_loss: 0.0447 - val_accuracy: 0.8359\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0315 - accuracy: 0.9894 - val_loss: 0.0448 - val_accuracy: 0.8750\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0326 - accuracy: 0.9859 - val_loss: 0.0444 - val_accuracy: 0.8672\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0308 - accuracy: 0.9930 - val_loss: 0.0453 - val_accuracy: 0.8750\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.0480 - val_accuracy: 0.8594\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0396 - accuracy: 0.9789 - val_loss: 0.0503 - val_accuracy: 0.8750\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0250 - accuracy: 0.9965 - val_loss: 0.0491 - val_accuracy: 0.8594\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0349 - accuracy: 0.9859 - val_loss: 0.0473 - val_accuracy: 0.8516\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0261 - accuracy: 0.9894 - val_loss: 0.0459 - val_accuracy: 0.8359\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0327 - accuracy: 0.9859 - val_loss: 0.0442 - val_accuracy: 0.8672\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0318 - accuracy: 0.9859 - val_loss: 0.0434 - val_accuracy: 0.8828\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 0.0441 - val_accuracy: 0.8828\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0280 - accuracy: 0.9894 - val_loss: 0.0450 - val_accuracy: 0.8672\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0406 - accuracy: 0.9718 - val_loss: 0.0452 - val_accuracy: 0.8594\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0316 - accuracy: 0.9824 - val_loss: 0.0467 - val_accuracy: 0.8438\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0311 - accuracy: 0.9824 - val_loss: 0.0454 - val_accuracy: 0.8438\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0335 - accuracy: 0.9859 - val_loss: 0.0457 - val_accuracy: 0.8594\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0357 - accuracy: 0.9930 - val_loss: 0.0453 - val_accuracy: 0.8594\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0443 - val_accuracy: 0.8438\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0268 - accuracy: 0.9859 - val_loss: 0.0449 - val_accuracy: 0.8438\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0313 - accuracy: 0.9824 - val_loss: 0.0450 - val_accuracy: 0.8516\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0309 - accuracy: 0.9789 - val_loss: 0.0448 - val_accuracy: 0.8594\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0372 - accuracy: 0.9789 - val_loss: 0.0452 - val_accuracy: 0.8672\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0264 - accuracy: 0.9824 - val_loss: 0.0448 - val_accuracy: 0.8828\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0399 - accuracy: 0.9754 - val_loss: 0.0439 - val_accuracy: 0.8672\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0408 - accuracy: 0.9930 - val_loss: 0.0457 - val_accuracy: 0.8672\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0293 - accuracy: 0.9859 - val_loss: 0.0430 - val_accuracy: 0.8672\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 0.0452 - val_accuracy: 0.8672\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0290 - accuracy: 0.9789 - val_loss: 0.0425 - val_accuracy: 0.8828\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0365 - accuracy: 0.9824 - val_loss: 0.0465 - val_accuracy: 0.8672\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0269 - accuracy: 0.9824 - val_loss: 0.0435 - val_accuracy: 0.8672\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0273 - accuracy: 0.9894 - val_loss: 0.0430 - val_accuracy: 0.8672\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0320 - accuracy: 0.9930 - val_loss: 0.0514 - val_accuracy: 0.8672\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0266 - accuracy: 0.9824 - val_loss: 0.0442 - val_accuracy: 0.8516\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0353 - accuracy: 0.9683 - val_loss: 0.0445 - val_accuracy: 0.8438\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0276 - accuracy: 0.9859 - val_loss: 0.0458 - val_accuracy: 0.8203\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0269 - accuracy: 0.9789 - val_loss: 0.0450 - val_accuracy: 0.8438\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0305 - accuracy: 0.9930 - val_loss: 0.0473 - val_accuracy: 0.8359\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0310 - accuracy: 0.9824 - val_loss: 0.0440 - val_accuracy: 0.8359\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0233 - accuracy: 0.9859 - val_loss: 0.0438 - val_accuracy: 0.8516\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0297 - accuracy: 0.9789 - val_loss: 0.0433 - val_accuracy: 0.8750\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0298 - accuracy: 0.9859 - val_loss: 0.0438 - val_accuracy: 0.8672\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0308 - accuracy: 0.9789 - val_loss: 0.0589 - val_accuracy: 0.8828\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0268 - accuracy: 0.9894 - val_loss: 0.0425 - val_accuracy: 0.8750\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0285 - accuracy: 0.9965 - val_loss: 0.0427 - val_accuracy: 0.8672\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0311 - accuracy: 0.9824 - val_loss: 0.0445 - val_accuracy: 0.8594\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0312 - accuracy: 0.9965 - val_loss: 0.0429 - val_accuracy: 0.8672\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0345 - accuracy: 0.9824 - val_loss: 0.0422 - val_accuracy: 0.8750\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0254 - accuracy: 0.9789 - val_loss: 0.0453 - val_accuracy: 0.8750\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0294 - accuracy: 0.9859 - val_loss: 0.0423 - val_accuracy: 0.8906\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0277 - accuracy: 0.9930 - val_loss: 0.0428 - val_accuracy: 0.8750\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0281 - accuracy: 0.9859 - val_loss: 0.0427 - val_accuracy: 0.8672\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0252 - accuracy: 0.9824 - val_loss: 0.0502 - val_accuracy: 0.8516\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 0.0458 - val_accuracy: 0.8516\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0275 - accuracy: 0.9930 - val_loss: 0.0442 - val_accuracy: 0.8203\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0291 - accuracy: 0.9824 - val_loss: 0.0479 - val_accuracy: 0.8359\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.0426 - val_accuracy: 0.8438\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.0462 - val_accuracy: 0.8203\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0283 - accuracy: 0.9824 - val_loss: 0.0484 - val_accuracy: 0.8203\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0297 - accuracy: 0.9789 - val_loss: 0.0440 - val_accuracy: 0.8203\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0272 - accuracy: 0.9789 - val_loss: 0.0467 - val_accuracy: 0.8203\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0339 - accuracy: 0.9718 - val_loss: 0.0430 - val_accuracy: 0.8516\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0260 - accuracy: 0.9824 - val_loss: 0.0487 - val_accuracy: 0.8516\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0287 - accuracy: 0.9859 - val_loss: 0.0423 - val_accuracy: 0.8750\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0230 - accuracy: 0.9894 - val_loss: 0.0451 - val_accuracy: 0.8750\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0218 - accuracy: 0.9859 - val_loss: 0.0429 - val_accuracy: 0.8750\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0313 - accuracy: 0.9859 - val_loss: 0.0411 - val_accuracy: 0.8672\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0206 - accuracy: 0.9894 - val_loss: 0.0413 - val_accuracy: 0.8672\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0231 - accuracy: 0.9894 - val_loss: 0.0483 - val_accuracy: 0.8750\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0277 - accuracy: 0.9859 - val_loss: 0.0491 - val_accuracy: 0.8672\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0242 - accuracy: 0.9894 - val_loss: 0.0453 - val_accuracy: 0.8672\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0248 - accuracy: 0.9894 - val_loss: 0.0563 - val_accuracy: 0.8516\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0286 - accuracy: 0.9859 - val_loss: 0.0535 - val_accuracy: 0.8438\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0205 - accuracy: 0.9859 - val_loss: 0.0549 - val_accuracy: 0.8516\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0235 - accuracy: 0.9894 - val_loss: 0.0440 - val_accuracy: 0.8672\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0284 - accuracy: 0.9859 - val_loss: 0.0470 - val_accuracy: 0.8672\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0337 - accuracy: 0.9824 - val_loss: 0.0429 - val_accuracy: 0.8672\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0261 - accuracy: 0.9824 - val_loss: 0.0461 - val_accuracy: 0.8672\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0241 - accuracy: 0.9894 - val_loss: 0.0535 - val_accuracy: 0.8672\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.0482 - val_accuracy: 0.8672\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0259 - accuracy: 0.9859 - val_loss: 0.0485 - val_accuracy: 0.8516\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0284 - accuracy: 0.9789 - val_loss: 0.0459 - val_accuracy: 0.8438\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0266 - accuracy: 0.9789 - val_loss: 0.0442 - val_accuracy: 0.8281\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0273 - accuracy: 0.9824 - val_loss: 0.0480 - val_accuracy: 0.8516\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0248 - accuracy: 0.9894 - val_loss: 0.0471 - val_accuracy: 0.8594\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0201 - accuracy: 0.9789 - val_loss: 0.0490 - val_accuracy: 0.8438\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0235 - accuracy: 0.9824 - val_loss: 0.0469 - val_accuracy: 0.8281\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0406 - accuracy: 0.9824 - val_loss: 0.0459 - val_accuracy: 0.8203\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0231 - accuracy: 0.9894 - val_loss: 0.0465 - val_accuracy: 0.8203\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0250 - accuracy: 0.9824 - val_loss: 0.0468 - val_accuracy: 0.8281\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 1s 375ms/step - loss: 0.0259 - accuracy: 0.9859 - val_loss: 0.0484 - val_accuracy: 0.8359\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0259 - accuracy: 0.9824 - val_loss: 0.0507 - val_accuracy: 0.8203\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0212 - accuracy: 0.9859 - val_loss: 0.0491 - val_accuracy: 0.8203\n",
      "Epoch 253/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 401ms/step - loss: 0.0194 - accuracy: 0.9894 - val_loss: 0.0485 - val_accuracy: 0.8203\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0351 - accuracy: 0.9754 - val_loss: 0.0446 - val_accuracy: 0.8281\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 1s 410ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0485 - val_accuracy: 0.8516\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0250 - accuracy: 0.9859 - val_loss: 0.0470 - val_accuracy: 0.8594\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0269 - accuracy: 0.9824 - val_loss: 0.0454 - val_accuracy: 0.8438\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.0261 - accuracy: 0.9859 - val_loss: 0.0477 - val_accuracy: 0.8281\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0250 - accuracy: 0.9894 - val_loss: 0.0433 - val_accuracy: 0.8438\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0250 - accuracy: 0.9894 - val_loss: 0.0512 - val_accuracy: 0.8438\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0258 - accuracy: 0.9894 - val_loss: 0.0426 - val_accuracy: 0.8594\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0244 - accuracy: 0.9894 - val_loss: 0.0485 - val_accuracy: 0.8672\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0268 - accuracy: 0.9859 - val_loss: 0.0484 - val_accuracy: 0.8672\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 1s 377ms/step - loss: 0.0208 - accuracy: 0.9894 - val_loss: 0.0495 - val_accuracy: 0.8672\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 1s 397ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.8750\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 1s 392ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0471 - val_accuracy: 0.8594\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.0258 - accuracy: 0.9859 - val_loss: 0.0414 - val_accuracy: 0.8672\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 1s 396ms/step - loss: 0.0270 - accuracy: 0.9859 - val_loss: 0.0476 - val_accuracy: 0.8438\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0273 - accuracy: 0.9824 - val_loss: 0.0442 - val_accuracy: 0.8359\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0367 - accuracy: 0.9718 - val_loss: 0.0438 - val_accuracy: 0.8438\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0298 - accuracy: 0.9824 - val_loss: 0.0439 - val_accuracy: 0.8281\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0271 - accuracy: 0.9754 - val_loss: 0.0446 - val_accuracy: 0.8281\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 1s 383ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0438 - val_accuracy: 0.8438\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0234 - accuracy: 0.9859 - val_loss: 0.0429 - val_accuracy: 0.8438\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0254 - accuracy: 0.9859 - val_loss: 0.0415 - val_accuracy: 0.8516\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 1s 387ms/step - loss: 0.0233 - accuracy: 0.9824 - val_loss: 0.0413 - val_accuracy: 0.8359\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0240 - accuracy: 0.9859 - val_loss: 0.0417 - val_accuracy: 0.8281\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0281 - accuracy: 0.9894 - val_loss: 0.0422 - val_accuracy: 0.8359\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0196 - accuracy: 0.9894 - val_loss: 0.0421 - val_accuracy: 0.8516\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0223 - accuracy: 0.9894 - val_loss: 0.0407 - val_accuracy: 0.8516\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0228 - accuracy: 0.9894 - val_loss: 0.0408 - val_accuracy: 0.8594\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0258 - accuracy: 0.9894 - val_loss: 0.0407 - val_accuracy: 0.8438\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 1s 395ms/step - loss: 0.0344 - accuracy: 0.9824 - val_loss: 0.0513 - val_accuracy: 0.8438\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 1s 390ms/step - loss: 0.0231 - accuracy: 0.9859 - val_loss: 0.0652 - val_accuracy: 0.8594\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0296 - accuracy: 0.9824 - val_loss: 0.0495 - val_accuracy: 0.8516\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 1s 374ms/step - loss: 0.0368 - accuracy: 0.9754 - val_loss: 0.0466 - val_accuracy: 0.8516\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 1s 388ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 0.0460 - val_accuracy: 0.8672\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 1s 385ms/step - loss: 0.0263 - accuracy: 0.9894 - val_loss: 0.0443 - val_accuracy: 0.8594\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 1s 379ms/step - loss: 0.0260 - accuracy: 0.9894 - val_loss: 0.0504 - val_accuracy: 0.8438\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0202 - accuracy: 0.9894 - val_loss: 0.0496 - val_accuracy: 0.8359\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 1s 382ms/step - loss: 0.0377 - accuracy: 0.9613 - val_loss: 0.0529 - val_accuracy: 0.8281\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 0.0226 - accuracy: 0.9859 - val_loss: 0.0557 - val_accuracy: 0.8359\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0212 - accuracy: 0.9859 - val_loss: 0.0495 - val_accuracy: 0.8359\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 1s 378ms/step - loss: 0.0277 - accuracy: 0.9718 - val_loss: 0.0485 - val_accuracy: 0.8281\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.0266 - accuracy: 0.9859 - val_loss: 0.0443 - val_accuracy: 0.8281\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 1s 394ms/step - loss: 0.0267 - accuracy: 0.9789 - val_loss: 0.0443 - val_accuracy: 0.8203\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 1s 384ms/step - loss: 0.0267 - accuracy: 0.9754 - val_loss: 0.0445 - val_accuracy: 0.8125\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.0569 - val_accuracy: 0.8359\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 1s 376ms/step - loss: 0.0235 - accuracy: 0.9824 - val_loss: 0.0528 - val_accuracy: 0.8516\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 1s 381ms/step - loss: 0.0263 - accuracy: 0.9824 - val_loss: 0.0585 - val_accuracy: 0.8359\n"
     ]
    }
   ],
   "source": [
    "# Will download and load pretrained imagenet weights.\n",
    "model = levit.LeViT256(input_shape=(400, 320, 1), num_classes = CLASSRS, use_distillation=False, classifier_activation=None)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, decay=0.01), \n",
    "#\n",
    "    loss = 'mse',\n",
    "#     loss ='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "    \n",
    "model_history = model.fit(train_image, train_label_categ,\n",
    "                      epochs=EPOCHS,\n",
    "                      batch_size=BATCH,\n",
    "                      validation_data=(test_image, test_label_categ),\n",
    "                      callbacks=[\n",
    "                          tensorboard_callback,\n",
    "                          model_checkpoint,\n",
    "#                           early_stopping_monitor,\n",
    "                      ],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b81724ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result = model.predict(test_image)\n",
    "\n",
    "predicted_result =  np.argmax(test_result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20440a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 4 4 0 4 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 3 3 3 0 4 3 3 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(test_label)\n",
    "print(predicted_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77731fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(test_label > 0, 1, 0))\n",
    "print(np.where(predicted_result > 0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7b12c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47452/2014205418.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minput_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0minput_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SE' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = (128,128, 3)\n",
    "input_layer = Input(input_shape)\n",
    "\n",
    "input_model = SE(input_layers)\n",
    "input_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb5c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
